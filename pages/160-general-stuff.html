<section data-transition="concave-in fade-out">
  <h1>General Remarks</h1>
  <p>
    <ul style="margin-left: -350px">
      <li class="fragment">Other Python decompilers</li>
      <li class="fragment">General-Purpose Decompilers</li>
      <li class="fragment">How Control Flow Differs</li>
      <li class="fragment">Choice of Intermediate Language</li>
    </ul>
  </p>


  <aside class="notes">
    <div style="color: blue; background-color: LightYellow">#/16
    </div>
    <p>
      Now that I have given a whirlwind tour of bytecode decompilation
      for these Python decompilers, let me back up and put this in
      place.
      <div style="color: blue; background-color: LightYellow">[DOWN] #/16/ ⟶ #/16/0/0
      </div>
    </p>

    <p>
      There are other decompilers for Python. They all start out with
      a disassembly, even the one I looked at that uses Machine
      Learning. Many build a tree &mdash; more or less &mdash; based
      on instructions from a disasssembly, and then all produce source
      text from that internal tree-ish structure.
    </p>

    <p>
      However, they are a bit more ad hoc. None use the
      grammar-based approach here. The phases are fewer and a little
      less distinct.
      <div style="color: blue; background-color: LightYellow">[DOWN]
	#/16/0/0 ⟶ #/16/0/1
      </div>
    </p>

    <p>
      General-purpose decompilers like you find in Ghidra, are largely
      different. They live in a more complicated world. To be able to
      do things across a wider spectrum of machine languages, and a
      wider spectrum of programming-language environments, they
      largely give up on the hope of noticing specific patterns of
      instructions, like we showed in the chained-comparison
      example. The ability to match specific patterns is what makes
      these decompilers produce extremely intuitive and accurate
      results and written in the programming language that the source
      text was also written in.
      <div style="color: blue; background-color: LightYellow">[DOWN]
	#/16/0/1 ⟶ #/16/0/2
      </div>
    </p>

    <p>
      Control Flow, in General-purpose decompilers, is its own canned
      phase. This phase doesn’t take into account the specific target
      programming language that produced the code or the specific set
      of control-flow structures that the source language has.
    </p>

    <p>
      Our control flow is intimately tied to the control flow for a
      particular Python version. When Python added a new construct like
      "async" coroutines in Python 3.5, it added a new kind of
      control-flow pattern match. Python has an <em>extremely</em> rich
      set of control-flow structures. I know of no canned
      control-flow-detection mechanism that would be able to
      cover <em>all</em> control-flow mechanisms that Python includes
      like the "else" clauses on "while", "for", and "try"
      blocks.
      <div style="color: blue; background-color: LightYellow">[DOWN] #/16/0/2 ⟶ #/16/0/3
      </div>
    </p>

    <p>
      Our approach uses tokenization to facilitated parsing. This is
      similar to the "lift" phase that general-purpose decompilers
      often do after initial disassembly. In general-purpose
      decompilers, the lifting language is sometimes to LLVM or an
      LLVM-like language. In Python, our Intermediate language is very
      much tied to Python Bytecode. In general, that is true for all
      high-level bytecode decompilers: the intermediate code looks
      like the high-level bytecode. Also, this intermediate language
      drifts over time along with the language and bytecode
      drift.
      <div style="color: blue; background-color: LightYellow">[NEXT] #/16/0/3 ⟶ #/16/0/3
      </div>
    </p>
  </aside>
</section>
